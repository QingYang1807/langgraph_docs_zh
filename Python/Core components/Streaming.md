# æµå¼ä¼ è¾“ï¼ˆStreamingï¼‰

LangChain å®ç°äº†ä¸€å¥—ç”¨äºå®æ—¶æ›´æ–°çš„æµå¼ä¼ è¾“ç³»ç»Ÿã€‚

æµå¼ä¼ è¾“å¯¹äºæå‡åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨å“åº”é€Ÿåº¦è‡³å…³é‡è¦ã€‚é€šè¿‡åœ¨å®Œæ•´å“åº”ç”Ÿæˆä¹‹å‰é€æ­¥å±•ç¤ºè¾“å‡ºå†…å®¹ï¼Œæµå¼ä¼ è¾“å¯ä»¥æ˜¾è‘—æ”¹å–„ç”¨æˆ·ä½“éªŒï¼ˆUXï¼‰ï¼Œå°¤å…¶åœ¨é¢å¯¹æ¨¡å‹æ¨ç†å»¶è¿Ÿæ—¶æ•ˆæœæ˜¾è‘—ã€‚

---

## æ¦‚è¿°

LangChain çš„æµå¼ç³»ç»Ÿå¯ä»¥è®©ä½ çš„åº”ç”¨å®æ—¶è·å–æ™ºèƒ½ä½“ï¼ˆAgentï¼‰çš„æ‰§è¡Œåé¦ˆã€‚

LangChain çš„æµå¼ä¼ è¾“èƒ½åšåˆ°ä»¥ä¸‹å‡ ç‚¹ï¼š

* ğŸ§  **[æµå¼å±•ç¤ºæ™ºèƒ½ä½“è¿›åº¦](#æ™ºèƒ½ä½“è¿›åº¦)** â€”â€” æ¯å½“æ™ºèƒ½ä½“æ‰§è¡Œä¸€ä¸ªæ­¥éª¤æ—¶ï¼Œå°±ä¼šå‘é€çŠ¶æ€æ›´æ–°ã€‚
* ğŸ”¢ **[æµå¼è¾“å‡º LLM token](#llm-token)** â€”â€” éšç€è¯­è¨€æ¨¡å‹ç”Ÿæˆ tokenï¼Œå®æ—¶è¾“å‡ºã€‚
* ğŸ“Š **[æµå¼è¾“å‡ºè‡ªå®šä¹‰æ›´æ–°](#è‡ªå®šä¹‰æ›´æ–°)** â€”â€” å‘å‡ºè‡ªå®šä¹‰ä¿¡å·ï¼ˆä¾‹å¦‚ï¼šâ€œå·²è·å– 10/100 æ¡è®°å½•â€ï¼‰ã€‚
* ğŸ§© **[å¤šæ¨¡å¼æµå¼ä¼ è¾“](#å¤šæ¨¡å¼æµå¼ä¼ è¾“)** â€”â€” æ”¯æŒ `updates`ï¼ˆè¿›åº¦æ›´æ–°ï¼‰ã€`messages`ï¼ˆLLM token + å…ƒæ•°æ®ï¼‰ã€`custom`ï¼ˆç”¨æˆ·è‡ªå®šä¹‰æ•°æ®ï¼‰ç­‰å¤šç§æ¨¡å¼ã€‚

---

## æ™ºèƒ½ä½“è¿›åº¦

è‹¥è¦æµå¼ä¼ è¾“æ™ºèƒ½ä½“è¿›åº¦ï¼Œå¯ä½¿ç”¨
[`stream`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.stream)
æˆ–
[`astream`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.astream)
æ–¹æ³•ï¼Œå¹¶è®¾ç½® `stream_mode="updates"`ã€‚è¿™ä¼šåœ¨æ¯ä¸ªæ­¥éª¤æ‰§è¡Œåå‘å‡ºäº‹ä»¶ã€‚

ä¾‹å¦‚ï¼Œä¸€ä¸ªä»…è°ƒç”¨ä¸€æ¬¡å·¥å…·çš„æ™ºèƒ½ä½“å°†äº§ç”Ÿå¦‚ä¸‹æ›´æ–°ï¼š

* **LLM èŠ‚ç‚¹**ï¼š[`AIMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.AIMessage)ï¼Œè¡¨ç¤ºå‘èµ·å·¥å…·è°ƒç”¨è¯·æ±‚
* **Tool èŠ‚ç‚¹**ï¼š[`ToolMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.ToolMessage)ï¼Œè¡¨ç¤ºå·¥å…·æ‰§è¡Œç»“æœ
* **LLM èŠ‚ç‚¹**ï¼šæœ€ç»ˆç”Ÿæˆçš„ AI å›å¤

```python title="æµå¼å±•ç¤ºæ™ºèƒ½ä½“è¿›åº¦"
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”"""
    return f"{city}çš„å¤©æ°”æ°¸è¿œæ™´æœ—ï¼"

agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[get_weather],
)

for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”å¦‚ä½•ï¼Ÿ"}]},
    stream_mode="updates",
):
    for step, data in chunk.items():
        print(f"æ­¥éª¤: {step}")
        print(f"å†…å®¹: {data['messages'][-1].content_blocks}")
```

è¾“å‡ºç¤ºä¾‹ï¼š

```shell
æ­¥éª¤: model
å†…å®¹: [{'type': 'tool_call', 'name': 'get_weather', 'args': {'city': 'San Francisco'}}]

æ­¥éª¤: tools
å†…å®¹: [{'type': 'text', 'text': "It's always sunny in San Francisco!"}]

æ­¥éª¤: model
å†…å®¹: [{'type': 'text', 'text': "It's always sunny in San Francisco!"}]
```

---

## LLM Token

å¦‚æœå¸Œæœ›éšç€ LLM ç”Ÿæˆ token å®æ—¶æ¥æ”¶è¾“å‡ºï¼Œå¯ä½¿ç”¨ `stream_mode="messages"`ã€‚

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†æµå¼è¾“å‡ºå·¥å…·è°ƒç”¨è¿‡ç¨‹åŠæœ€ç»ˆå›å¤ï¼š

```python title="æµå¼è¾“å‡º LLM token"
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[get_weather],
)

for token, metadata in agent.stream(
    {"messages": [{"role": "user", "content": "What is the weather in SF?"}]},
    stream_mode="messages",
):
    print(f"èŠ‚ç‚¹: {metadata['langgraph_node']}")
    print(f"å†…å®¹: {token.content_blocks}\n")
```

è¾“å‡ºç»“æœï¼ˆèŠ‚é€‰ï¼‰ï¼š

```shell
node: model
content: [{'type': 'tool_call_chunk', 'name': 'get_weather', 'args': '{"city":"San Francisco"}'}]
...
node: tools
content: [{'type': 'text', 'text': "It's always sunny in San Francisco!"}]
...
node: model
content: [{'type': 'text', 'text': 'San Francisco weather: It\'s always sunny in San Francisco!'}]
```

---

## è‡ªå®šä¹‰æ›´æ–°

è‹¥è¦ä»å·¥å…·ä¸­æµå¼è¾“å‡ºè‡ªå®šä¹‰ä¿¡æ¯ï¼Œå¯ä½¿ç”¨
[`get_stream_writer`](https://reference.langchain.com/python/langgraph/config/#langgraph.config.get_stream_writer)ã€‚

```python title="æµå¼è¾“å‡ºè‡ªå®šä¹‰æ›´æ–°"
from langchain.agents import create_agent
from langgraph.config import get_stream_writer

def get_weather(city: str) -> str:
    writer = get_stream_writer()
    writer(f"æ­£åœ¨æŸ¥æ‰¾ {city} çš„æ•°æ®...")
    writer(f"å·²è·å– {city} çš„æ•°æ®")
    return f"{city}å¤©æ°”æ°¸è¿œæ™´æœ—ï¼"

agent = create_agent(
    model="anthropic:claude-sonnet-4-5",
    tools=[get_weather],
)

for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”å¦‚ä½•ï¼Ÿ"}]},
    stream_mode="custom"
):
    print(chunk)
```

è¾“å‡ºç¤ºä¾‹ï¼š

```shell
æ­£åœ¨æŸ¥æ‰¾ San Francisco çš„æ•°æ®...
å·²è·å– San Francisco çš„æ•°æ®
```

> ğŸ’¡ æ³¨æ„ï¼š
> å¦‚æœåœ¨å·¥å…·å‡½æ•°ä¸­ä½¿ç”¨äº† `get_stream_writer()`ï¼Œåˆ™è¯¥å·¥å…·æ— æ³•åœ¨ LangGraph æ‰§è¡Œä¸Šä¸‹æ–‡ä¹‹å¤–è°ƒç”¨ã€‚

---

## å¤šæ¨¡å¼æµå¼ä¼ è¾“

å¯ä»¥é€šè¿‡ä¼ å…¥åˆ—è¡¨æŒ‡å®šå¤šç§æµæ¨¡å¼ï¼Œä¾‹å¦‚ï¼š
`stream_mode=["updates", "custom"]`

```python title="å¤šæ¨¡å¼æµå¼ä¼ è¾“"
from langchain.agents import create_agent
from langgraph.config import get_stream_writer

def get_weather(city: str) -> str:
    writer = get_stream_writer()
    writer(f"æ­£åœ¨æŸ¥æ‰¾ {city} çš„æ•°æ®...")
    writer(f"å·²è·å– {city} çš„æ•°æ®")
    return f"{city}å¤©æ°”æ°¸è¿œæ™´æœ—ï¼"

agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[get_weather],
)

for mode, chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”å¦‚ä½•ï¼Ÿ"}]},
    stream_mode=["updates", "custom"]
):
    print(f"æµæ¨¡å¼: {mode}")
    print(f"å†…å®¹: {chunk}\n")
```

è¾“å‡ºç»“æœåŒ…å«ä¸¤ç±»ä¿¡æ¯ï¼šæ™ºèƒ½ä½“æ‰§è¡Œè¿›åº¦ï¼ˆupdatesï¼‰ä¸è‡ªå®šä¹‰æ—¥å¿—ï¼ˆcustomï¼‰ã€‚

---

## ç¦ç”¨æµå¼ä¼ è¾“

åœ¨æŸäº›åœºæ™¯ä¸‹ï¼Œä½ å¯èƒ½å¸Œæœ›å…³é—­æ¨¡å‹çš„ token æµå¼è¾“å‡ºã€‚
ä¾‹å¦‚åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œå¯ä»¥åªè®©éƒ¨åˆ†æ™ºèƒ½ä½“å¯ç”¨æµå¼è¾“å‡ºä»¥å‡å°‘å¹²æ‰°ã€‚

å‚è§ [Models æŒ‡å—](https://python.langchain.com/oss/langchain/models#disable-streaming) äº†è§£å¦‚ä½•ç¦ç”¨æµå¼ä¼ è¾“ã€‚

---

ğŸ’¡ **æç¤º**
ä½ å¯ä»¥é€šè¿‡ [MCP æ¥å£](/use-these-docs) å°†è¿™äº›æ–‡æ¡£æ¥å…¥ Claudeã€VSCode ç­‰ç¯å¢ƒï¼Œå®ç°å®æ—¶æŸ¥è¯¢ã€‚
