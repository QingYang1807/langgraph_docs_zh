# LangChain å¿«é€Ÿä¸Šæ‰‹ï¼ˆQuickstart ä¸­æ–‡ç‰ˆï¼‰

æœ¬æ•™ç¨‹å°†å¸¦ä½ åœ¨å‡ åˆ†é’Ÿå†…ï¼Œä»é›¶æ­å»ºä¸€ä¸ª **å¯è¿è¡Œçš„ AI æ™ºèƒ½ä½“ï¼ˆAgentï¼‰**ã€‚
ä½ å°†å­¦ä¼šå¦‚ä½•æ„å»ºã€é…ç½®ã€è¿è¡Œå¹¶æŒç»­äº¤äº’ä¸€ä¸ªâ€œå…·å¤‡è®°å¿†ä¸å·¥å…·è°ƒç”¨èƒ½åŠ›â€çš„ LangChain æ™ºèƒ½ä½“ã€‚

---

## ğŸš€ 1. æ„å»ºåŸºç¡€æ™ºèƒ½ä½“

ä¸‹é¢ç¤ºä¾‹å±•ç¤ºäº†æœ€åŸºç¡€çš„æ™ºèƒ½ä½“ï¼š

* æ¨¡å‹ï¼šClaude Sonnet 4.5
* å·¥å…·ï¼šå¤©æ°”æŸ¥è¯¢å‡½æ•°
* ç³»ç»Ÿæç¤ºè¯ï¼šå®šä¹‰ Agent è¡Œä¸º

```python
from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚å¤©æ°”"""
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="anthropic:claude-sonnet-4-5",
    tools=[get_weather],
    system_prompt="You are a helpful assistant",
)

# è°ƒç”¨æ™ºèƒ½ä½“
agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather in sf"}]}
)
```

> ğŸ’¡ æç¤ºï¼š
> æœ¬ä¾‹éœ€åœ¨ç³»ç»Ÿç¯å¢ƒä¸­è®¾ç½® Anthropic API Key
>
> ```bash
> export ANTHROPIC_API_KEY="your_api_key_here"
> ```

---

## ğŸŒ¦ï¸ 2. æ„å»ºçœŸå®ä¸–ç•Œæ™ºèƒ½ä½“ï¼ˆWeather Agentï¼‰

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ›´å®Œæ•´çš„å¤©æ°”é¢„æŠ¥æ™ºèƒ½ä½“ï¼Œå®ƒå…·å¤‡ï¼š

1. **è§’è‰²æç¤ºï¼ˆSystem Promptï¼‰**ï¼šå®šä¹‰è¯­æ°”ä¸è¡Œä¸ºï¼›
2. **å¤–éƒ¨å·¥å…·è°ƒç”¨ï¼ˆToolsï¼‰**ï¼šä»å¤–éƒ¨è·å–æ•°æ®ï¼›
3. **æ¨¡å‹é…ç½®ï¼ˆModel Configï¼‰**ï¼šæ§åˆ¶è¾“å‡ºä¸€è‡´æ€§ï¼›
4. **ç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰**ï¼šè®©å“åº”æ›´å¯è§£æï¼›
5. **è®°å¿†èƒ½åŠ›ï¼ˆMemoryï¼‰**ï¼šè®©å¯¹è¯å…·å¤‡ä¸Šä¸‹æ–‡ï¼›
6. **ä¸Šä¸‹æ–‡æ³¨å…¥ï¼ˆContextï¼‰**ï¼šæ”¯æŒç”¨æˆ·çº§ä¸ªæ€§åŒ–ã€‚

---

### ğŸ§± Step 1ï¼šå®šä¹‰ç³»ç»Ÿæç¤ºï¼ˆSystem Promptï¼‰

```python
SYSTEM_PROMPT = """You are an expert weather forecaster, who speaks in puns.

You have access to two tools:

- get_weather_for_location: use this to get the weather for a specific location
- get_user_location: use this to get the user's location

If a user asks you for the weather, make sure you know the location.
If you can tell from the question that they mean wherever they are,
use the get_user_location tool to find their location."""
```

---

### ğŸ”§ Step 2ï¼šå®šä¹‰å·¥å…·ï¼ˆToolsï¼‰

å·¥å…·å…è®¸æ¨¡å‹æ‰§è¡Œå‡½æ•°è°ƒç”¨ï¼Œä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’ã€‚

```python
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime

@tool
def get_weather_for_location(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚å¤©æ°”"""
    return f"It's always sunny in {city}!"

@dataclass
class Context:
    """è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼ˆè‡ªå®šä¹‰ç»“æ„ï¼‰"""
    user_id: str

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """æ ¹æ®ç”¨æˆ·IDè·å–ä½ç½®"""
    user_id = runtime.context.user_id
    return "Florida" if user_id == "1" else "SF"
```

> ğŸ’¡ å·¥å…·æ–‡æ¡£ï¼ˆå‡½æ•°åã€å‚æ•°åã€è¯´æ˜ï¼‰ä¼šè‡ªåŠ¨è¢«æ³¨å…¥æ¨¡å‹æç¤ºä¸­ã€‚

---

### ğŸ§  Step 3ï¼šé…ç½®æ¨¡å‹ï¼ˆModel Configurationï¼‰

```python
from langchain.chat_models import init_chat_model

model = init_chat_model(
    "anthropic:claude-sonnet-4-5",
    temperature=0.5,
    timeout=10,
    max_tokens=1000
)
```

---

### ğŸ“„ Step 4ï¼šå®šä¹‰å“åº”ç»“æ„ï¼ˆResponse Formatï¼‰

```python
from dataclasses import dataclass

@dataclass
class ResponseFormat:
    """æ™ºèƒ½ä½“å“åº”ç»“æ„"""
    punny_response: str  # åŒå…³è¯­å¼å›åº”ï¼ˆå¿…å¡«ï¼‰
    weather_conditions: str | None = None  # å¯é€‰å¤©æ°”è¯¦æƒ…
```

---

### ğŸ’¾ Step 5ï¼šæ·»åŠ è®°å¿†ï¼ˆMemoryï¼‰

ä½¿ç”¨ `InMemorySaver` åœ¨çŸ­æœŸå†…ä¿å­˜ä¸Šä¸‹æ–‡å¯¹è¯ã€‚
ç”Ÿäº§ç¯å¢ƒä¸­å¯æ”¹ä¸ºæ•°æ®åº“æŒä¹…åŒ–ã€‚

```python
from langgraph.checkpoint.memory import InMemorySaver

checkpointer = InMemorySaver()
```

---

### ğŸ§  Step 6ï¼šåˆ›å»ºå¹¶è¿è¡Œæ™ºèƒ½ä½“ï¼ˆCreate & Run Agentï¼‰

```python
from langchain.agents import create_agent

agent = create_agent(
    model=model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ResponseFormat,
    checkpointer=checkpointer
)

# å”¯ä¸€çº¿ç¨‹IDï¼Œç”¨äºç»´æŒå¯¹è¯
config = {"configurable": {"thread_id": "1"}}

response = agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather outside?"}]},
    config=config,
    context=Context(user_id="1")
)

print(response['structured_response'])
```

è¾“å‡ºç¤ºä¾‹ï¼š

```python
ResponseFormat(
    punny_response="Florida is still having a 'sun-derful' day!...",
    weather_conditions="It's always sunny in Florida!"
)
```

---

### ğŸ” Step 7ï¼šè¿ç»­å¯¹è¯ï¼ˆConversation Continuityï¼‰

ä½¿ç”¨ç›¸åŒ `thread_id` å¯ä¿æŒä¸Šä¸‹æ–‡è®°å¿†ï¼š

```python
response = agent.invoke(
    {"messages": [{"role": "user", "content": "thank you!"}]},
    config=config,
    context=Context(user_id="1")
)

print(response['structured_response'])
# ResponseFormat(
#     punny_response="You're 'thund-erfully' welcome!...",
#     weather_conditions=None
# )
```

---

## ğŸ§© å®Œæ•´ç¤ºä¾‹ä»£ç 

```python
from dataclasses import dataclass
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model
from langchain.tools import tool, ToolRuntime
from langgraph.checkpoint.memory import InMemorySaver

SYSTEM_PROMPT = """You are an expert weather forecaster, who speaks in puns.

You have access to two tools:
- get_weather_for_location
- get_user_location
"""

@dataclass
class Context:
    user_id: str

@tool
def get_weather_for_location(city: str) -> str:
    return f"It's always sunny in {city}!"

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    return "Florida" if runtime.context.user_id == "1" else "SF"

model = init_chat_model("anthropic:claude-sonnet-4-5", temperature=0)
checkpointer = InMemorySaver()

@dataclass
class ResponseFormat:
    punny_response: str
    weather_conditions: str | None = None

agent = create_agent(
    model=model,
    system_prompt=SYSTEM_PROMPT,
    tools=[get_user_location, get_weather_for_location],
    context_schema=Context,
    response_format=ResponseFormat,
    checkpointer=checkpointer
)

config = {"configurable": {"thread_id": "1"}}
response = agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather outside?"}]},
    config=config,
    context=Context(user_id="1")
)
print(response['structured_response'])
```

---

## ğŸ¯ ä½ ç°åœ¨å·²ç»æŒæ¡äº†ä¸€ä¸ªå®Œæ•´å¯ç”¨çš„ LangChain æ™ºèƒ½ä½“ï¼

å®ƒå¯ä»¥ï¼š

âœ… ç†è§£ä¸Šä¸‹æ–‡ã€ç»´æŒå¯¹è¯çŠ¶æ€
âœ… è°ƒç”¨å¤šä¸ªå¤–éƒ¨å·¥å…·
âœ… è¿”å›ç»“æ„åŒ–è¾“å‡ºæ ¼å¼
âœ… åŸºäºç”¨æˆ·ä¸Šä¸‹æ–‡åŠ¨æ€å“åº”
âœ… æ”¯æŒæŒä¹…åŒ–è®°å¿†ä¸å¤šè½®äº¤äº’

---

âœï¸ [åœ¨ GitHub ä¸Šç¼–è¾‘æœ¬é¡µ](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/quickstart.mdx)
ğŸ’» [é€šè¿‡ MCP æ¥å…¥ Claudeã€VSCode ç­‰å·¥å…·ï¼Œå®ç°å®æ—¶é—®ç­”](/use-these-docs)
